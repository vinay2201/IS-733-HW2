{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa204614-e555-47a9-bae5-62fbfdb93bc0",
   "metadata": {},
   "source": [
    "## IS 733 - Data Mining\n",
    "## Homework 2\n",
    "### - Vinay Krishna Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c94a32a-39e8-4926-9eaa-2e714b71f09c",
   "metadata": {},
   "source": [
    "#### 1) Read  red-wine.csv into Python as a data frame, use a pandas profiling tool (https://github.com/pandas-profiling/pandas-profiling) to create an HTML file, and paste a screenshot of the HTML file here (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f0de06-6c44-4a4c-a4c8-8513de9c8c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb80f496411413087a139e04f60a1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e035bb21c0054b05b8a64138901fc40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5dd8335a73445488c067b65ff9b64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd869485fc46448c8fc2fe39f6b2a297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "path = \"D:/IS 733/HW2/red_wine.csv\"\n",
    "red_wine_data = pd.read_csv(path)\n",
    "\n",
    "profile = ProfileReport(red_wine_data, title = \"Red Wine Dataset Report\")\n",
    "\n",
    "profile.to_file(\"D:/IS 733/HW2/report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc54bc9-9ebd-4781-a3e7-9056470889e8",
   "metadata": {},
   "source": [
    "#### 2) Fit a model using each of the following methods and report the performance metrics of\n",
    "#### 10-fold cross-validation using red-wine.csv as the training set (30 points).\n",
    "#### Note:\n",
    "#### ● You are not required to tune the parameter for this homework assignment.\n",
    "#### ● You can use the default parameter for each model.\n",
    "#### ● Baseline model accuracy is the accuracy when predicting the majority class;\n",
    "#### Baseline model AUC is the random classifier AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414b167-e3a2-49e8-bccd-97f31f108059",
   "metadata": {},
   "source": [
    "#### Baseline model using majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0640d88f-6aeb-41bc-a0c1-9dab3748d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288966725043783\n"
     ]
    }
   ],
   "source": [
    "majority_class = red_wine_data['type'].value_counts().idxmax()\n",
    "baseline_accuracy = (red_wine_data['type'] == majority_class).mean()\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e9eed-4ea8-4f4f-8583-20d1fd8bac0a",
   "metadata": {},
   "source": [
    "#### Baseline Model using DummyClassifier library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b8c3ec-6730-4d7d-90a7-5359a34d70b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model - Majority Class Classifier:\n",
      "Mean Accuracy: 0.528886872353297\n",
      "Mean AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = red_wine_data.drop(columns=['type'])\n",
    "y = LabelEncoder().fit_transform(red_wine_data['type'])\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "mean_accuracy = cross_val_score(dummy_clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "mean_auc = cross_val_score(dummy_clf, X, y, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "print(\"Baseline Model - Majority Class Classifier:\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Mean AUC: {mean_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef19aef-2dbc-4f66-8422-87630a7257a7",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1212f6f-c35c-4f3a-863a-685c7e23542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7847852389594676\n",
      "Logistic Regression AUC: 0.8799019697944429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "logreg_accuracy = cross_val_score(logreg_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "logreg_auc = cross_val_score(logreg_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Logistic Regression AUC: {logreg_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a977551-3b25-4d2a-9638-ad07697caba1",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0377f7d3-4de7-462b-8501-707cef609d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8216273442226255\n",
      "Naive Bayes AUC: 0.8954078975584352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naivebayes_model = GaussianNB()\n",
    "\n",
    "naivebayes_accuracy = cross_val_score(naivebayes_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "naivebayes_auc = cross_val_score(naivebayes_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {naivebayes_accuracy}\")\n",
    "print(f\"Naive Bayes AUC: {naivebayes_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b6308-dca4-404a-8a0c-6f4af39aeebf",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0768e6aa-c2f7-41ab-a61b-6e56360b5d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7497277676950997\n",
      "Decision Tree AUC: 0.7535277088502895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "dt_accuracy = cross_val_score(dt_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "dt_auc = cross_val_score(dt_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "print(f\"Decision Tree AUC: {dt_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e27b4a-b245-45f2-9116-675c09993bcf",
   "metadata": {},
   "source": [
    "#### SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7beeb7-9603-475c-babf-fd9b6b4b1605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-Linear Accuracy: 0.7918632788868724\n",
      "SVM-Linear AUC: 0.8814885274025059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_linear_model = SVC(kernel = 'linear', probability = True)\n",
    "\n",
    "svm_linear_accuracy = cross_val_score(svm_linear_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "svm_linear_auc = cross_val_score(svm_linear_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"SVM-Linear Accuracy: {svm_linear_accuracy}\")\n",
    "print(f\"SVM-Linear AUC: {svm_linear_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574532a-e6c9-4c3e-b45c-9dea922e1d10",
   "metadata": {},
   "source": [
    "#### SVM -RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9da901d-d9ae-4508-a886-688adac49a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-RBF Accuracy: 0.5358439201451907\n",
      "SVM-RBF AUC: 0.8689201360169102\n"
     ]
    }
   ],
   "source": [
    "svm_rbf_model = SVC(kernel = 'rbf', probability = True)\n",
    "\n",
    "svm_rbf_accuracy = cross_val_score(svm_rbf_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "svm_rbf_auc = cross_val_score(svm_rbf_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"SVM-RBF Accuracy: {svm_rbf_accuracy}\")\n",
    "print(f\"SVM-RBF AUC: {svm_rbf_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9156295-aa97-48b6-93f2-bcee9e61949e",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8554d1b6-d9b3-40fa-9a88-88478e4f3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.802389594676346\n",
      "Random Forest AUC: 0.8882530711025336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_accuracy = cross_val_score(rf_model, X, y, cv = 10, scoring = 'accuracy').mean()\n",
    "rf_auc = cross_val_score(rf_model, X, y, cv = 10, scoring = 'roc_auc').mean()\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Random Forest AUC: {rf_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a26092-f017-4324-80f1-a77bbe3edfe3",
   "metadata": {},
   "source": [
    "#### 3) Plot the ROC curve of the Random Forest classifier from the Python package, and paste a screenshot of your ROC curve here (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b9e2db-9790-4909-8ad4-1288eea9f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "aucs = []\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=f'Mean ROC (AUC = {mean_auc:.2f})', lw=2, alpha=0.8)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve - Random Forest (10-fold CV)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.savefig(\"D:/IS 733/HW2/ROC_Random_Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d8469-d7f5-4d70-81cd-d1fb422c7b29",
   "metadata": {},
   "source": [
    "#### 4) Using the best model obtained above in Q2 (according to AUC), running the model on white-wine.csv, and reporting the AUC score, comment on the performance. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b5a218f-0394-4c90-820d-6f71756f2492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Wine Random Forest Accuracy: 0.9232142857142858\n",
      "White Wine Random Forest AUC: 0.9416666666666668\n"
     ]
    }
   ],
   "source": [
    "w_wine_path = \"D:/IS 733/HW2/white_wine.csv\"\n",
    "white_wine_data = pd.read_csv(w_wine_path)\n",
    "\n",
    "X1 = white_wine_data.drop(columns=['type'])\n",
    "y1 = LabelEncoder().fit_transform(white_wine_data['type']) \n",
    "\n",
    "white_wine_model = RandomForestClassifier()\n",
    "\n",
    "white_wine_accuracy = cross_val_score(white_wine_model, X1, y1, cv=10, scoring='accuracy').mean()\n",
    "white_wine_auc = cross_val_score(white_wine_model, X1, y1, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "print(f\"White Wine Random Forest Accuracy: {white_wine_accuracy}\")\n",
    "print(f\"White Wine Random Forest AUC: {white_wine_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c162458-737f-4507-a2d9-ae741bb257ca",
   "metadata": {},
   "source": [
    "The performance of the Random Forest model performs well on both white wine and red wine datasets, demonstrating the ability of the model to generalize well across different type of wine types.\n",
    "The high AUC score suggests that the model is making accurate predictions on the white wine dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24bb14-0aff-49c4-a38e-60984072f85c",
   "metadata": {},
   "source": [
    "#### 5) Suppose all the models have comparable performance. Which model would you prefer if the wine-tasting experts would like to gain some insights into the model? Note: there could be multiple model types fitting this criterion. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a7605-d21a-45cf-9c49-6b0fe6671bed",
   "metadata": {},
   "source": [
    "A Decision Tree is highly interpretable because it provides a clear and visual representation of decisions in the form of a tree structure. \n",
    "Logistic Regression offers high transparency. It provides a linear relationship between input features and the target variable, making it straightforward to interpret.\n",
    "Given the need for interpretability and actionable insights, Decision Trees and Logistic Regression remain the best options because the goal is to drive wine-tasting experts to understand what is happening inside the model and make decisions based on the features leading to these predicted results from the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
